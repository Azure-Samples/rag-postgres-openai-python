# Use these values to connect to the local database from within the devcontainer
POSTGRES_HOST=localhost
POSTGRES_USERNAME=admin
POSTGRES_PASSWORD=postgres
POSTGRES_DATABASE=postgres
POSTGRES_SSL=disable

# OPENAI_CHAT_HOST can be either azure, openai, ollama, or github:
OPENAI_CHAT_HOST=azure
# OPENAI_EMBED_HOST can be either azure, openai, ollama, or github:
OPENAI_EMBED_HOST=azure
# Needed for Azure:
# You also need to `azd auth login` if running this locally
AZURE_OPENAI_ENDPOINT=https://YOUR-AZURE-OPENAI-SERVICE-NAME.openai.azure.com
AZURE_OPENAI_VERSION=2024-03-01-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_CHAT_MODEL=gpt-4o-mini
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-3-large
AZURE_OPENAI_EMBED_MODEL=text-embedding-3-large
AZURE_OPENAI_EMBED_DIMENSIONS=1024
AZURE_OPENAI_EMBEDDING_COLUMN=embedding_3l
AZURE_OPENAI_EVAL_DEPLOYMENT=gpt-4
AZURE_OPENAI_EVAL_MODEL=gpt-4
AZURE_TENANT_ID=
# Only needed when using key-based Azure authentication:
AZURE_OPENAI_KEY=
# Needed for OpenAI.com:
OPENAICOM_KEY=YOUR-OPENAI-API-KEY
OPENAICOM_CHAT_MODEL=gpt-3.5-turbo
OPENAICOM_EMBED_MODEL=text-embedding-3-large
OPENAICOM_EMBED_DIMENSIONS=1024
OPENAICOM_EMBEDDING_COLUMN=embedding_3l
# Needed for Ollama:
OLLAMA_ENDPOINT=http://host.docker.internal:11434/v1
OLLAMA_CHAT_MODEL=llama3.1
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_EMBEDDING_COLUMN=embedding_nomic
# Needed for GitHub Models:
GITHUB_TOKEN=YOUR-GITHUB-TOKEN
GITHUB_BASE_URL=https://models.inference.ai.azure.com
GITHUB_MODEL=gpt-4o
GITHUB_EMBED_MODEL=text-embedding-3-large
GITHUB_EMBED_DIMENSIONS=1024
GITHUB_EMBEDDING_COLUMN=embedding_3l
