# Use these values to connect to the local database from within the devcontainer
POSTGRES_HOST=localhost
POSTGRES_USERNAME=admin
POSTGRES_PASSWORD=postgres
POSTGRES_DATABASE=postgres
POSTGRES_SSL=disable

# OPENAI_CHAT_HOST can be either azure, openai, or ollama:
OPENAI_CHAT_HOST=azure
# OPENAI_EMBED_HOST can be either azure or openai:
OPENAI_EMBED_HOST=azure
# Needed for Azure:
# You also need to `azd auth login` if running this locally
AZURE_OPENAI_ENDPOINT=https://YOUR-AZURE-OPENAI-SERVICE-NAME.openai.azure.com
AZURE_OPENAI_VERSION=2024-03-01-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_CHAT_MODEL=gpt-4o-mini
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-ada-002
AZURE_OPENAI_EMBED_MODEL=text-embedding-ada-002
AZURE_OPENAI_EMBED_DIMENSIONS=1536
AZURE_OPENAI_EMBEDDING_COLUMN=embedding_ada002
AZURE_OPENAI_EVAL_DEPLOYMENT=gpt-4
AZURE_OPENAI_EVAL_MODEL=gpt-4
AZURE_TENANT_ID=
# Only needed when using key-based Azure authentication:
AZURE_OPENAI_KEY=
# Needed for OpenAI.com:
OPENAICOM_KEY=YOUR-OPENAI-API-KEY
OPENAICOM_CHAT_MODEL=gpt-3.5-turbo
OPENAICOM_EMBED_MODEL=text-embedding-ada-002
OPENAICOM_EMBED_MODEL_DIMENSIONS=1536
OPENAICOM_EMBEDDING_COLUMN=embedding_ada002
# Needed for Ollama:
OLLAMA_ENDPOINT=http://host.docker.internal:11434/v1
OLLAMA_CHAT_MODEL=llama3.1
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_EMBEDDING_COLUMN=embedding_nomic
